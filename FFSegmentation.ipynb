{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xmOpjeFJhbs"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzR-5u5OpOm-"
      },
      "source": [
        "### Installations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLsc2jzOg8WL",
        "outputId": "894af432-b6e2-4267-fbdd-d4243d57c619"
      },
      "outputs": [],
      "source": [
        "!pip install segmentation-models-pytorch\n",
        "!pip install torchmetrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3c_PwARnpRkS"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "drt62pIbJTEs"
      },
      "outputs": [],
      "source": [
        "from pycocotools.coco import COCO\n",
        "import numpy as np\n",
        "import os\n",
        "from IPython.display import clear_output\n",
        "import segmentation_models_pytorch as smp\n",
        "import torchvision\n",
        "import torch\n",
        "import torchmetrics as tm\n",
        "import PIL\n",
        "import random\n",
        "import cv2\n",
        "torchvision.disable_beta_transforms_warning()\n",
        "import torchvision.transforms.v2 as transforms\n",
        "\n",
        "### For visualizing the outputs ###\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "%matplotlib inline\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0x2LNbppeR3"
      },
      "source": [
        "# Loading Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-g1uBVG_pU77"
      },
      "source": [
        "### Functions for loading COCO dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DuMcf0jcJkQK"
      },
      "outputs": [],
      "source": [
        "def filterDataset(folder, classes=None, mode='train'):    \n",
        "    # initialize COCO api for instance annotations\n",
        "    annFile = '{}/annotations/coco-{}.json'.format(folder, mode)\n",
        "    # annFile = '{}/annotations/coco.json'.format(folder)\n",
        "    coco = COCO(annFile)\n",
        "    \n",
        "    images = []\n",
        "    if classes!=None:\n",
        "        # iterate for each individual class in the list\n",
        "        for className in classes:\n",
        "            # get all images containing given categories\n",
        "            catIds = coco.getCatIds(catNms=className)\n",
        "            imgIds = coco.getImgIds(catIds=catIds)\n",
        "            images += coco.loadImgs(imgIds)\n",
        "    \n",
        "    else:\n",
        "        imgIds = coco.getImgIds()\n",
        "        images = coco.loadImgs(imgIds)\n",
        "    \n",
        "    # Now, filter out the repeated images\n",
        "    unique_images = []\n",
        "    for i in range(len(images)):\n",
        "        if images[i] not in unique_images:\n",
        "            unique_images.append(images[i])\n",
        "            \n",
        "    random.shuffle(unique_images)\n",
        "    dataset_size = len(unique_images)\n",
        "    \n",
        "    return unique_images, dataset_size, coco\n",
        "\n",
        "def getClassName(classID, cats):\n",
        "    for i in range(len(cats)):\n",
        "        if cats[i]['id']==classID:\n",
        "            return cats[i]['name']\n",
        "    return None\n",
        "\n",
        "def getImage(imageObj, img_folder, input_image_size):\n",
        "    # Read and normalize an image\n",
        "    # train_img = io.imread(img_folder + '/' + imageObj['file_name'])/255.0\n",
        "    train_img = torchvision.io.read_image(img_folder + '/' + imageObj['file_name'])/255.0\n",
        "    # train_img = io.imread(img_folder + '/' + imageObj['file_name'])\n",
        "    # train_img = preprocess_input(train_img)\n",
        "    # train_img = tf.keras.applications.resnet50.preprocess_input(train_img)\n",
        "    # Resize\n",
        "    # train_img = cv2.resize(train_img, input_image_size)\n",
        "    train_img = torchvision.transforms.Resize(size=input_image_size)(train_img)\n",
        "    if (len(train_img.shape)==3 and train_img.shape[0]==3): # If it is a RGB 3 channel image\n",
        "        return train_img\n",
        "    else: # To handle a black and white image, increase dimensions to 3\n",
        "        stacked_img = np.stack((train_img,)*3, axis=-1)\n",
        "        return stacked_img\n",
        "    \n",
        "def getNormalMask(imageObj, classes, coco, catIds, input_image_size):\n",
        "    annIds = coco.getAnnIds(imageObj['id'], catIds=catIds, iscrowd=None)\n",
        "    anns = coco.loadAnns(annIds)\n",
        "    cats = coco.loadCats(catIds)\n",
        "    train_mask = np.zeros(input_image_size)\n",
        "    for a in range(len(anns)):\n",
        "        className = getClassName(anns[a]['category_id'], cats)\n",
        "        pixel_value = classes.index(className)+1\n",
        "        new_mask = cv2.resize(coco.annToMask(anns[a])*pixel_value, input_image_size)\n",
        "        train_mask = np.maximum(new_mask, train_mask)\n",
        "\n",
        "    # Add extra dimension for parity with train_img size [X * X * 3]\n",
        "    train_mask = train_mask.reshape(1, input_image_size[0], input_image_size[1])\n",
        "    return train_mask  \n",
        "    \n",
        "def getBinaryMask(imageObj, coco, catIds, input_image_size):\n",
        "    annIds = coco.getAnnIds(imageObj['id'], catIds=catIds, iscrowd=None)\n",
        "    anns = coco.loadAnns(annIds)\n",
        "    train_mask = np.zeros(input_image_size)\n",
        "    for a in range(len(anns)):\n",
        "        new_mask = cv2.resize(coco.annToMask(anns[a]), input_image_size)\n",
        "        \n",
        "        #Threshold because resizing may cause extraneous values\n",
        "        new_mask[new_mask >= 0.5] = 1\n",
        "        new_mask[new_mask < 0.5] = 0\n",
        "\n",
        "        train_mask = np.maximum(new_mask, train_mask)\n",
        "\n",
        "    # Add extra dimension for parity with train_img size [X * X * 3]\n",
        "    train_mask = train_mask.reshape(input_image_size[0], input_image_size[1], 1)\n",
        "    return train_mask\n",
        "\n",
        "\n",
        "def dataGeneratorCoco(images, classes, coco, folder, \n",
        "                      input_image_size=(224,224), batch_size=4, mode='train', mask_type='binary'):\n",
        "    \n",
        "    img_folder = '{}/images/{}'.format(folder, mode)\n",
        "    # img_folder = '{}/images'.format(folder)\n",
        "    dataset_size = len(images)\n",
        "    catIds = coco.getCatIds(catNms=classes)\n",
        "    \n",
        "    c = 0\n",
        "    while(True):\n",
        "        img = np.zeros((batch_size, 3, input_image_size[0], input_image_size[1])).astype('float')\n",
        "        mask = np.zeros((batch_size, 1, input_image_size[0], input_image_size[1])).astype('float')\n",
        "\n",
        "        for i in range(c, c+batch_size): #initially from 0 to batch_size, when c = 0\n",
        "            imageObj = images[i]\n",
        "            \n",
        "            ### Retrieve Image ###\n",
        "            train_img = getImage(imageObj, img_folder, input_image_size)\n",
        "            # print(train_img.shape)\n",
        "\n",
        "            ### Create Mask ###\n",
        "            if mask_type==\"binary\":\n",
        "                train_mask = getBinaryMask(imageObj, coco, catIds, input_image_size)\n",
        "            \n",
        "            elif mask_type==\"normal\":\n",
        "                train_mask = getNormalMask(imageObj, classes, coco, catIds, input_image_size)                \n",
        "            \n",
        "            # Add to respective batch sized arrays\n",
        "            img[i-c] = train_img\n",
        "            mask[i-c] = train_mask\n",
        "            \n",
        "        c+=batch_size\n",
        "        if(c + batch_size >= dataset_size):\n",
        "            c=0\n",
        "            random.shuffle(images)\n",
        "        yield img, mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jImOZjjcJ4UT",
        "outputId": "14a1f25a-a6ae-451c-d1a2-41ee5ac534a2"
      },
      "outputs": [],
      "source": [
        "folder = '/content/drive/MyDrive/COCOdatasettomato'\n",
        "# classes = ['laptop', 'tv', 'cell phone']\n",
        "# classes = None\n",
        "classes = ['Leaf', 'Leaf_Diseased', 'Background']\n",
        "mode = 'train'\n",
        "\n",
        "images, dataset_size, coco = filterDataset(folder, classes, mode)\n",
        "catIds = coco.getCatIds(catNms=classes)\n",
        "\n",
        "\n",
        "print(images)\n",
        "print(dataset_size)\n",
        "print(coco)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6T_TytmplWK"
      },
      "source": [
        "### Load into arrays"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPXPyQhPLVNF",
        "outputId": "12ac9172-18e9-4310-cce3-fc02efda4471"
      },
      "outputs": [],
      "source": [
        "input_image_size = (512,512)\n",
        "\n",
        "train_images = []\n",
        "train_masks = []\n",
        "val_images = []\n",
        "val_masks = []\n",
        "\n",
        "\n",
        "'''\n",
        "train images\n",
        "'''\n",
        "images, dataset_size, coco = filterDataset(folder, classes, mode='train')\n",
        "\n",
        "# train_images = torch.empty(size=(len(images), 3, input_image_size[0], input_image_size[0]))\n",
        "train_images = np.empty((len(images), 3, input_image_size[0], input_image_size[0]), dtype=np.uint8)\n",
        "# train_masks = torch.empty(size=(len(images), 3, input_image_size[0], input_image_size[0]))\n",
        "train_masks = np.empty((len(images), 3, input_image_size[0], input_image_size[0]), dtype=np.uint8)\n",
        "\n",
        "for i, img_json in enumerate(images):\n",
        "  filename = img_json['file_name']\n",
        "  path = folder+'/images/train'\n",
        "  img = torchvision.io.read_image(path + '/' + filename)\n",
        "  img = torchvision.transforms.functional.resize(img, input_image_size)\n",
        "  mask = getNormalMask(img_json, classes, coco, catIds, input_image_size) \n",
        "  mask = mask.astype(int)\n",
        "  rgb_mask = np.zeros((3, 512, 512), dtype=np.uint8)\n",
        "  rgb_mask[0] = (mask == 0) * 255\n",
        "  rgb_mask[1] = (mask == 1) * 255\n",
        "  rgb_mask[2] = (mask == 2) * 255\n",
        "  mask = rgb_mask\n",
        "  train_images[i] = img.detach().clone()\n",
        "  train_masks[i] = torch.tensor(mask)\n",
        "'''\n",
        "val images\n",
        "'''\n",
        "images, dataset_size, coco = filterDataset(folder, classes, mode='val')\n",
        "\n",
        "# val_images = torch.empty(size=(len(images), 3, input_image_size[0], input_image_size[0]))\n",
        "val_images = np.empty((len(images), 3, input_image_size[0], input_image_size[0]), dtype=np.uint8)\n",
        "# val_masks = torch.empty(size=(len(images), 3, input_image_size[0], input_image_size[0]))\n",
        "val_masks = np.empty((len(images), 3, input_image_size[0], input_image_size[0]), dtype=np.uint8)\n",
        "\n",
        "for i, img_json in enumerate(images):\n",
        "  filename = img_json['file_name']\n",
        "  path = folder+'/images/val'\n",
        "  img = torchvision.io.read_image(path + '/' + filename)\n",
        "  img = torchvision.transforms.functional.resize(img, input_image_size)\n",
        "  mask = getNormalMask(img_json, classes, coco, catIds, input_image_size) \n",
        "  mask = mask.astype(int)\n",
        "  rgb_mask = np.zeros((3, 512, 512), dtype=np.uint8)\n",
        "  rgb_mask[0] = (mask == 0) * 255\n",
        "  rgb_mask[1] = (mask == 1) * 255\n",
        "  rgb_mask[2] = (mask == 2) * 255\n",
        "  mask = rgb_mask\n",
        "  val_images[i] = img.detach().clone()\n",
        "  val_masks[i] = torch.tensor(mask)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vx7pUyQCppj9"
      },
      "source": [
        "### Visualize Mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 853
        },
        "id": "lDxLFz3QSx5L",
        "outputId": "b381190f-07a8-4dcc-969a-0d2a9170d2e2"
      },
      "outputs": [],
      "source": [
        "plt.imshow(np.transpose(train_images[0], (2,1,0)))\n",
        "plt.show()\n",
        "plt.imshow(np.transpose(train_masks[0], (2,1,0)))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_pzPcbRpsYa"
      },
      "source": [
        "### Dataset Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZujV0rXrY_j3"
      },
      "outputs": [],
      "source": [
        "class COCOdataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, image_tensor, mask_tensor, transform=None):\n",
        "        self.image_tensor = image_tensor\n",
        "        self.mask_tensor = mask_tensor\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_tensor)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.image_tensor[idx]\n",
        "        mask = self.mask_tensor[idx]\n",
        "\n",
        "        image = PIL.Image.fromarray(np.transpose(image, (2,1,0)))\n",
        "        mask = PIL.Image.fromarray(np.transpose(mask, (2,1,0)))\n",
        "\n",
        "        # seed = np.random.randint(2147483647)  # generate a random seed\n",
        "        # random.seed(seed)\n",
        "        # torch.manual_seed(0)\n",
        "\n",
        "        image, mask = self.transform(image, mask)\n",
        "\n",
        "        '''\n",
        "        remove one hot\n",
        "        '''\n",
        "        mask = torch.argmax(mask, dim=0).unsqueeze(0)\n",
        "        # image = np.transpose(image, (1,0,2))\n",
        "        # mask = np.transpose(mask, (1,0,2))\n",
        "        # print(image.shape, mask.shape)\n",
        "        return image, mask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWBHhQ_KpvdS"
      },
      "source": [
        "### Load into Dataset Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOdtXremadPf",
        "outputId": "12a2ac7b-f625-41f7-8d48-3d818d5f632c"
      },
      "outputs": [],
      "source": [
        "batch_size = 8\n",
        "\n",
        "'''\n",
        "define transformations\n",
        "'''\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),  # Randomly flip the image horizontally\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.RandomAdjustSharpness(0.5),\n",
        "    transforms.RandomRotation(360),\n",
        "    # transforms.RandomRotation(360, fill=(255,0,0)),\n",
        "    # torchvision.transforms.Normalize([0.5,0.5,0.5], [0.5,0.5,0.5]),\n",
        "    transforms.ToTensor(),           # Convert the image to a tensor\n",
        "])\n",
        "\n",
        "train_dataset = COCOdataset(train_images, train_masks, transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_dataset = COCOdataset(val_images, val_masks, transform=transform)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFGDisRlpz5J"
      },
      "source": [
        "### Visualize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gcD4eeDvbj6j",
        "outputId": "59e576f7-8756-4b71-e3e2-6ce2f05d8139"
      },
      "outputs": [],
      "source": [
        "images, masks = next(iter(train_loader))\n",
        "for i, (image, mask) in enumerate(zip(images,masks)):\n",
        "  # mask = torch.argmax(mask, dim=0).unsqueeze(0)\n",
        "  plt.imshow(np.transpose(image, (2,1,0)))\n",
        "  plt.show()\n",
        "  plt.imshow(np.transpose(mask, (2,1,0)))\n",
        "  plt.show()\n",
        "  print(np.unique(mask))\n",
        "\n",
        "# print(len(train_loader))\n",
        "# for i, (images, masks) in enumerate(iter(train_loader)):\n",
        "#   plt.imshow(np.transpose(images[0], (2,1,0)))\n",
        "#   plt.show()\n",
        "#   plt.imshow(np.transpose(masks[0], (2,1,0)))\n",
        "#   plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mv6_-pBKl_Ev"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBZejO47o4GW"
      },
      "source": [
        "### Helper Functions and Assign Device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Az2Ldk9yl88S",
        "outputId": "e15777f2-a201-4c76-fac8-793be883563e"
      },
      "outputs": [],
      "source": [
        "# check GPU availability\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "    print(torch.cuda.get_device_name(device))\n",
        "else:\n",
        "    device = None\n",
        "    print('GPU is not available')\n",
        "\n",
        "# def get_metrics(preds, masks):\n",
        "#   tp, fp, fn, tn = smp.metrics.get_stats(preds.unsqueeze(1), masks, mode='multiclass', num_classes=3)\n",
        "\n",
        "#   precision = sum(tp) / (sum(tp) + sum(fp))\n",
        "#   recall = sum(tp) / (sum(tp) + sum(fn))\n",
        "#   accuracy = (sum(tp) + sum(tn)) / (sum(tp)+sum(fp)+sum(tn)+sum(fn))\n",
        "#   f1 = 2*precision*recall / (precision + recall)\n",
        "  \n",
        "#   return (precision, recall, accuracy, f1)\n",
        "\n",
        "def get_metrics(tp, fp, fn, tn):\n",
        "\n",
        "  precision = (tp) / ((tp) + (fp))\n",
        "  recall = (tp) / ((tp) + (fn))\n",
        "  accuracy = ((tp) + (tn)) / ((tp)+(fp)+(tn)+(fn))\n",
        "  f1 = 2*precision*recall / (precision + recall)\n",
        "  \n",
        "  return (precision, recall, accuracy, f1)\n",
        "\n",
        "def get_stats(preds, masks):\n",
        "  tp, fp, fn, tn = smp.metrics.get_stats(preds.unsqueeze(1), masks, mode='multiclass', num_classes=3)\n",
        "  \n",
        "  return (tp, fp, fn, tn)\n",
        "\n",
        "def print_metrics(p,r,a,f1):\n",
        "  for i, (_p,_r,_a,_f1) in enumerate(zip(p,r,a,f1)):\n",
        "    if torch.any(torch.isnan(_p)) or torch.any(torch.isnan(_r)) or torch.any(torch.isnan(_a)) or torch.any(torch.isnan(_f1)): \n",
        "      break\n",
        "    print('   P       R       A       F1')\n",
        "    print(f'{i}: {_p:.4f}   {_r:.4f}   {_a:.4f}   {_f1:.4f}')\n",
        "\n",
        "def display(display_list):\n",
        "  plt.figure(figsize=(15, 15))\n",
        "\n",
        "  title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
        "\n",
        "  for i in range(len(display_list)):\n",
        "    plt.subplot(1, len(display_list), i+1)\n",
        "    plt.title(title[i])\n",
        "    plt.imshow(tf.keras.utils.array_to_img(display_list[i]))\n",
        "    plt.axis('off')\n",
        "  plt.show()\n",
        "\n",
        "def show_predictions(images, true_masks, pred_masks):\n",
        "    \"\"\"\n",
        "    Show the original image, true mask, and predicted mask for each image in the batch.\n",
        "    \n",
        "    Args:\n",
        "    images: tensor of shape (batch_size, channels, height, width) representing the batch of images\n",
        "    true_masks: tensor of shape (batch_size, 1, height, width) representing the true masks for the batch of images\n",
        "    pred_masks: tensor of shape (batch_size, 1, height, width) representing the predicted masks for the batch of images\n",
        "    \"\"\"\n",
        "\n",
        "    # Convert the tensors to numpy arrays\n",
        "    images = images.cpu().numpy()\n",
        "    true_masks = true_masks.cpu().numpy()\n",
        "    pred_masks = pred_masks.cpu().numpy()\n",
        "\n",
        "    # Loop over the images in the batch\n",
        "    for i in range(images.shape[0]):\n",
        "        # Create a new figure\n",
        "        fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(10, 5))\n",
        "        \n",
        "        # Show the original image\n",
        "        axes[0].imshow(np.transpose(images[i], (1, 2, 0)))\n",
        "        axes[0].set_title('Original Image')\n",
        "        axes[0].axis('off')\n",
        "        \n",
        "        # Show the true mask\n",
        "        axes[1].imshow(np.transpose(true_masks[i], (1, 2, 0)), cmap='gray')\n",
        "        axes[1].set_title('True Mask')\n",
        "        axes[1].axis('off')\n",
        "        \n",
        "        # Show the predicted mask\n",
        "        axes[2].imshow(pred_masks[i], cmap='gray')\n",
        "        axes[2].set_title('Predicted Mask')\n",
        "        axes[2].axis('off')\n",
        "        \n",
        "        # Show the figure\n",
        "        plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNa0S4IbqUXY"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zIha-7Ayo-rc",
        "outputId": "89238275-ccc6-4cde-ab5c-f53f5eec4a6a"
      },
      "outputs": [],
      "source": [
        "train_size = len(train_dataset)\n",
        "val_size = len(val_dataset)\n",
        "steps_per_epoch = train_size // batch_size\n",
        "validation_steps = val_size // batch_size\n",
        "\n",
        "'''\n",
        "Define Model\n",
        "'''\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch\n",
        "from segmentation_models_pytorch.encoders import get_preprocessing_fn\n",
        "\n",
        "\n",
        "# create model\n",
        "# model = smp.UnetPlusPlus(encoder_name='resnet34', encoder_weights='imagenet', in_channels=3, classes=3)\n",
        "# model = smp.UnetPlusPlus(encoder_name='resnet50', encoder_weights='imagenet', in_channels=3, classes=3)\n",
        "model = smp.UnetPlusPlus(encoder_name='mobilenet_v2', encoder_weights='imagenet', in_channels=3, classes=3)\n",
        "\n",
        "model = model.to(device=device)\n",
        "\n",
        "preprocess_input = get_preprocessing_fn('mobilenet_v2', pretrained='imagenet')\n",
        "'''\n",
        "Hyper Parameters\n",
        "'''\n",
        "# optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001) # 0.001\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3)\n",
        "# Define your loss function\n",
        "# loss_function = nn.CrossEntropyLoss().to(device)\n",
        "# loss_function = nn.CrossEntropyLoss(weight=torch.tensor([0.2,0.2,0.6])).to(device)\n",
        "loss_function = smp.losses.JaccardLoss(mode='multiclass').to(device)\n",
        "# loss_disease = smp.losses.JaccardLoss(mode='multiclass', classes=[2]).to(device)\n",
        "# loss_other = smp.losses.JaccardLoss(mode='multiclass', classes=[0,1]).to(device)\n",
        "# def lf(preds, true):\n",
        "#   return 2*loss_disease(preds,true) + loss_other(preds,true)\n",
        "# loss_function = lf\n",
        "\n",
        "'''\n",
        "Take sample\n",
        "'''\n",
        "sample_images, sample_masks = next(iter(val_loader))\n",
        "# sample_images = torch.from_numpy(sample_images)\n",
        "# sample_masks = torch.from_numpy(sample_masks)\n",
        "sample_images = sample_images.to(device=device)\n",
        "sample_masks = sample_masks.to(device=device)\n",
        "\n",
        "'''\n",
        "Lists for Plots\n",
        "'''\n",
        "train_loss_list = []\n",
        "val_loss_list = []\n",
        "train_p_list = []\n",
        "train_r_list = []\n",
        "val_p_list = []\n",
        "val_r_list = []\n",
        "\n",
        "'''\n",
        "Training\n",
        "'''\n",
        "num_epochs = 80\n",
        "steps_per_epoch = 32\n",
        "for epoch in range(num_epochs):\n",
        "    train_tp = torch.tensor([0,0,0])\n",
        "    train_fp = torch.tensor([0,0,0])\n",
        "    train_tn = torch.tensor([0,0,0])\n",
        "    train_fn = torch.tensor([0,0,0])\n",
        "    val_tp = torch.tensor([0,0,0])\n",
        "    val_fp = torch.tensor([0,0,0])\n",
        "    val_tn = torch.tensor([0,0,0])\n",
        "    val_fn = torch.tensor([0,0,0])\n",
        "    print('Epoch: ' + str(epoch))\n",
        "    train_loss = 0.0\n",
        "    val_loss = 0.0\n",
        "    model.train()\n",
        "    for i, (images, masks_) in enumerate(iter(train_loader)):\n",
        "        # print(str(step) + ' of ' + str(steps_per_epoch))\n",
        "        # masks = masks_.squeeze(1)\n",
        "        masks = masks_\n",
        "        # masks = torch.from_numpy(masks).long()\n",
        "        # masks = torch.argmax(masks, dim=1)  # Convert one-hot masks to integer indices\n",
        "        images = images.to(device=device)\n",
        "        masks = masks.to(device=device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "\n",
        "        loss = loss_function(outputs, masks)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item() * images.size(0)\n",
        "\n",
        "        probs = torch.softmax(outputs, dim=1)\n",
        "        _, labels = torch.max(probs, dim=1)\n",
        "\n",
        "        tp, fp, fn, tn = get_stats(labels, masks)\n",
        "        train_tp += tp.sum(dim=0)\n",
        "        train_fp += fp.sum(dim=0)\n",
        "        train_fn += fn.sum(dim=0)\n",
        "        train_tn += tn.sum(dim=0)\n",
        "    p, r, a, f1 = get_metrics(train_tp, train_fp, train_fn, train_tn)\n",
        "    print_metrics(p, r, a, f1)\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for i, (images, masks_) in enumerate(iter(val_loader)):\n",
        "            # masks = masks_.squeeze(1)\n",
        "            masks = masks_\n",
        "            # masks = torch.from_numpy(masks).long()\n",
        "            # masks = torch.argmax(masks, dim=1)  # Convert one-hot masks to integer indices\n",
        "            images = images.to(device=device)\n",
        "            masks = masks.to(device=device)\n",
        "            outputs = model(images)\n",
        "\n",
        "            loss = loss_function(outputs, masks)\n",
        "            val_loss += loss.item() * images.size(0)\n",
        "            \n",
        "            probs = torch.softmax(outputs, dim=1)\n",
        "            _, labels = torch.max(probs, dim=1)\n",
        "            \n",
        "            tp, fp, fn, tn = get_stats(labels, masks)\n",
        "            val_tp += tp.sum(dim=0)\n",
        "            val_fp += fp.sum(dim=0)\n",
        "            val_fn += fn.sum(dim=0)\n",
        "            val_tn += tn.sum(dim=0)\n",
        "    val_loss /= ((val_size // batch_size)*2)\n",
        "    # update learning rate\n",
        "    scheduler.step(val_loss)\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, train_loss: {train_loss}, val_loss: {val_loss}\")\n",
        "    p, r, a, f1 = get_metrics(val_tp, val_fp, val_fn, val_tn)\n",
        "    print_metrics(p, r, a, f1)\n",
        "    '''\n",
        "    append to lists\n",
        "    '''\n",
        "    train_loss_list.append(train_loss)\n",
        "    val_loss_list.append(val_loss)\n",
        "\n",
        "    outputs = model(sample_images)\n",
        "    # Apply softmax activation function to the output\n",
        "    probs = torch.softmax(outputs, dim=1)\n",
        "    # Get the predicted labels\n",
        "    _, labels = torch.max(probs, dim=1)\n",
        "    show_predictions(sample_images, sample_masks, labels)\n",
        "\n",
        "    # plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "ig0VIjM2Wjuw",
        "outputId": "25883826-6cbc-494d-a2f5-9606d8f8aaa1"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot the train and validation loss curves\n",
        "plt.plot(train_loss_list, label='Train Loss')\n",
        "plt.plot(val_loss_list, label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Train and Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dSfusGL8Wo71",
        "outputId": "fa0b5236-af44-470c-dca1-1d983d81a6ac"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "images, masks = next(iter(val_loader))\n",
        "images = images.to(device=device)\n",
        "masks = masks.to(device=device)\n",
        "outputs = model(images)\n",
        "# Apply softmax activation function to the output\n",
        "probs = torch.softmax(outputs, dim=1)\n",
        "# Get the predicted labels\n",
        "_, labels = torch.max(probs, dim=1)\n",
        "\n",
        "show_predictions(images, masks, labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jZiEvxDNdk8L"
      },
      "outputs": [],
      "source": [
        "torch.save(model, '/content/drive/MyDrive/saved_seg_models/mobilenetv3-80ep')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XImm0lG9d7N7"
      },
      "source": [
        "# Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ev69dFy0d8Ny"
      },
      "outputs": [],
      "source": [
        "eval_model = torch.load('/content/drive/MyDrive/saved_seg_models/mobilenetv2.3')\n",
        "eval_model.train(mode=False)\n",
        "eval_model = eval_model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xp_jDH6TeC6R",
        "outputId": "b3d2f976-4485-43a0-aec3-63aa8ad4ef11"
      },
      "outputs": [],
      "source": [
        "# total_tp = torch.from_numpy(np.zeros_like([\n",
        "#     [0,0,0],\n",
        "#     [0,0,0],\n",
        "#     [0,0,0],\n",
        "#     [0,0,0],\n",
        "#     [0,0,0],\n",
        "#     [0,0,0],\n",
        "#     [0,0,0],\n",
        "#     [0,0,0]\n",
        "# ]))\n",
        "# total_fp = torch.from_numpy(np.zeros_like(total_tp))\n",
        "# total_tn = torch.from_numpy(np.zeros_like(total_tp))\n",
        "# total_fn = torch.from_numpy(np.zeros_like(total_tp))\n",
        "total_tp = 0\n",
        "total_fp = 0\n",
        "total_tn = 0\n",
        "total_fn = 0\n",
        "\n",
        "for i, (images, masks) in enumerate(iter(train_loader)):\n",
        "  # if i > 0:\n",
        "  #   break\n",
        "  images = images.to(device=device)\n",
        "  masks = masks.to(device=device)\n",
        "  outputs = eval_model(images)\n",
        "  # Apply softmax activation function to the output\n",
        "  probs = torch.softmax(outputs, dim=1)\n",
        "  # Get the predicted labels\n",
        "  _, labels = torch.max(probs, dim=1)\n",
        "\n",
        "  tp, fp, fn, tn = get_stats(labels, masks)\n",
        "  print(tp)\n",
        "  if tp.size(0) < batch_size:\n",
        "    diff = batch_size - tp.size(0)\n",
        "    bigger = torch.zeros((tp.size(0)+diff, 3)).long()\n",
        "    bigger[:tp.shape[0], :] = tp\n",
        "    tp = bigger\n",
        "    bigger = torch.zeros((fp.size(0)+diff, 3)).long()\n",
        "    bigger[:fp.shape[0], :] = fp\n",
        "    fp = bigger\n",
        "    bigger = torch.zeros((fn.size(0)+diff, 3)).long()\n",
        "    bigger[:fn.shape[0], :] = fn\n",
        "    fn = bigger\n",
        "    bigger = torch.zeros((tn.size(0)+diff, 3)).long()\n",
        "    bigger[:tn.shape[0], :] = tn\n",
        "    tn = bigger\n",
        "  total_tp += tp\n",
        "  total_fp += fp\n",
        "  total_fn += fn\n",
        "  total_tn += tn\n",
        "  # p,r,a,f1 = get_metrics(tp,fp,fn,tn)\n",
        "  # print(p,r,a,f1)\n",
        "\n",
        "  # show_predictions(images, masks, labels)\n",
        "  \n",
        "  # iou_score = smp.metrics.iou_score(tp, fp, fn, tn, reduction=\"micro\")\n",
        "  # f1_score = smp.metrics.f1_score(tp, fp, fn, tn, reduction=\"micro\")\n",
        "  # f2_score = smp.metrics.fbeta_score(tp, fp, fn, tn, beta=2, reduction=\"micro\")\n",
        "  # accuracy = smp.metrics.accuracy(tp, fp, fn, tn, reduction=\"macro\")\n",
        "  # recall = smp.metrics.recall(tp, fp, fn, tn, reduction=\"micro-imagewise\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Go3zvr7JeETV",
        "outputId": "de89ec8f-43a3-4a91-d778-528b503b5cca"
      },
      "outputs": [],
      "source": [
        "# precision = total_tp / (total_tp + total_fp)\n",
        "# recall = total_tp / (total_tp + total_fn)\n",
        "precision = smp.metrics.precision(total_tp[:,2], total_fp[:,2], total_fn[:,2], total_tn[:,2], reduction='macro')\n",
        "recall = smp.metrics.recall(total_tp[:,2], total_fp[:,2], total_fn[:,2], total_tn[:,2], reduction='macro')\n",
        "precision, recall"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "HFGDisRlpz5J"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
